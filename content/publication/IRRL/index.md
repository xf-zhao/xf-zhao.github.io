---
title: Internally Rewarded Reinforcement Learning
authors: 
- Xufeng Zhao*
- Mengdi Li*
- Jae Hee Lee
- Cornelius Weber
- Stefan Wermter
journal: 
- ICML 2023
summary: We introduce Internally Rewarded Reinforcement Learning (IRRL), where rewards are generated by a jointly learned internal model rather than the environment. This coupling of policy and reward learning can destabilize training. We formalize IRRL, analyze its challenges, and propose a clipped linear reward function that reduces reward noise. Experiments show improved stability, faster convergence, and better performance across tasks.
tags:
- RL
- Robotics
date: "2023-06-27T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: "https://ir-rl.github.io/"

image:
  caption: 
  focal_point: Smart

# links:
# - icon: twitter
#   icon_pack: fab
#   name: Follow
#   url: https://twitter.com/georgecushen
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---
